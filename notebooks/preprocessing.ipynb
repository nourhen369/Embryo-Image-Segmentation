{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "80% train 10% validation 10% test\n",
        "4 data augmentation operations"
      ],
      "metadata": {
        "id": "UH46Fk-fMcq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from albumentations import *"
      ],
      "metadata": {
        "id": "1UcDwb7spotK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpeoIU-xzRUb",
        "outputId": "c22a0384-25f8-4a5c-9d89-db4f73e9a98e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dir(path):\n",
        "    \"\"\"Create a directory\"\"\"\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)"
      ],
      "metadata": {
        "id": "y5YR2Ot-prf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "\n",
        "    split=0.1 # 90% train&valid, 10%test\n",
        "    split2=0.1 # 80%train, 10% valid, 10% test\n",
        "\n",
        "    #dataset1_path = path + '/dataset1'\n",
        "    dataset1_path = '/content/drive/MyDrive/pfa-dataset1'\n",
        "\n",
        "    images = sorted(glob(f\"{dataset1_path}/Images/*.BMP\"))\n",
        "    masks_te = sorted(glob(f\"{dataset1_path}/GT_TE/*.bmp\"))\n",
        "    masks_icm = sorted(glob(f\"{dataset1_path}/GT_ICM/*.bmp\"))\n",
        "    masks_zp = sorted(glob(f\"{dataset1_path}/GT_ZP/*.bmp\"))\n",
        "    print(\"total dataset:\",len(masks_zp), len(masks_icm), len(masks_te), len(images))\n",
        "\n",
        "    \"\"\"Split data\"\"\"\n",
        "    split_size=round(split*len(images))#25 images for test\n",
        "    split_size2=round(split2*len(images))#25 images for valid, 199 train\n",
        "\n",
        "    train_i, test_i, train_te, test_te, train_zp, test_zp ,train_icm, test_icm = train_test_split(images,masks_te,masks_zp,masks_icm, test_size=split_size, random_state=42)\n",
        "    train_i, valid_i, train_te, valid_te, train_zp, valid_zp ,train_icm, valid_icm = train_test_split(train_i,train_te,train_zp,train_icm, test_size=split_size2, random_state=42)\n",
        "\n",
        "    print(\"train, valid, test\")\n",
        "    print(len(train_zp), len(valid_zp),len(test_zp))\n",
        "\n",
        "    return (train_i, test_i, valid_i), (train_zp, test_zp, valid_zp), (train_icm, test_icm, valid_icm), (train_te, test_te, valid_te)"
      ],
      "metadata": {
        "id": "D4Rl3O0GpuGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_this(image_file):\n",
        "\n",
        "    image_src = cv2.imread(image_file)\n",
        "    image_src = cv2.cvtColor(image_src, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    return image_src"
      ],
      "metadata": {
        "id": "NhDxCnMbpwy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_enhance(i, zp, icm, te):\n",
        "    W = 256\n",
        "    H = 256\n",
        "\n",
        "    i = cv2.resize(i, (W, H))\n",
        "    zp = cv2.resize(zp, (W, H))\n",
        "    icm = cv2.resize(icm, (W, H))\n",
        "    te = cv2.resize(te, (W, H))\n",
        "    #i = enhance_contrast(i)\n",
        "    i = i.astype('uint8')\n",
        "\n",
        "    return i, zp, icm, te"
      ],
      "metadata": {
        "id": "c0t-qq-PqCvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def augment_data(images, masks_zp, masks_icm, masks_te, new_path, train):\n",
        "    \"\"\"Performing data augmentation\"\"\"\n",
        "\n",
        "    print(len(images))\n",
        "    myvar=0\n",
        "    myvar2=0\n",
        "    myvar3=0\n",
        "    x=0\n",
        "\n",
        "    for idx, (i, zp, icm, te) in tqdm(enumerate(zip(images, masks_zp, masks_icm, masks_te)), total=len(images)):\n",
        "\n",
        "        name = i.split(\"/\")[-1].split(\".BMP\")[0]#corrected 20 aug\n",
        "\n",
        "        i = read_this(i)\n",
        "        zp = read_this(zp)\n",
        "        icm = read_this(icm)\n",
        "        te = read_this(te)\n",
        "\n",
        "        width, height = i.shape[0], i.shape[1]\n",
        "\n",
        "        if train:\n",
        "            myvar=myvar+1 #another train image processed\n",
        "\n",
        "            aug = Compose([\n",
        "\n",
        "                HorizontalFlip(p=1)\n",
        "\n",
        "            ], additional_targets={'mask_zp': 'mask', 'mask_icm': 'mask', 'mask_te': 'mask'})\n",
        "\n",
        "            augmented = aug(image=i, mask_zp=zp, mask_icm=icm, mask_te=te)\n",
        "            i1 = augmented['image']\n",
        "            zp1 = augmented['mask_zp']\n",
        "            icm1 = augmented['mask_icm']\n",
        "            te1 = augmented['mask_te']\n",
        "\n",
        "            aug = Compose([\n",
        "\n",
        "                VerticalFlip(p=1)\n",
        "\n",
        "            ], additional_targets={'mask_zp': 'mask', 'mask_icm': 'mask', 'mask_te': 'mask'})\n",
        "\n",
        "            augmented = aug(image=i, mask_zp=zp, mask_icm=icm, mask_te=te)\n",
        "            i2 = augmented['image']\n",
        "            zp2 = augmented['mask_zp']\n",
        "            icm2 = augmented['mask_icm']\n",
        "            te2 = augmented['mask_te']\n",
        "\n",
        "            aug = Compose([\n",
        "\n",
        "                Transpose(1)\n",
        "\n",
        "            ], additional_targets={'mask_zp': 'mask', 'mask_icm': 'mask', 'mask_te': 'mask'})\n",
        "\n",
        "            augmented = aug(image=i, mask_zp=zp, mask_icm=icm, mask_te=te)\n",
        "            i3 = augmented['image']\n",
        "            zp3 = augmented['mask_zp']\n",
        "            icm3 = augmented['mask_icm']\n",
        "            te3 = augmented['mask_te']\n",
        "\n",
        "            aug = Compose([\n",
        "\n",
        "                HorizontalFlip(p=1)\n",
        "\n",
        "            ], additional_targets={'mask_zp': 'mask', 'mask_icm': 'mask', 'mask_te': 'mask'})\n",
        "\n",
        "\n",
        "            augmented = aug(image=i3, mask_zp=zp3, mask_icm=icm3, mask_te=te3)\n",
        "            i4 = augmented['image']\n",
        "            zp4 = augmented['mask_zp']\n",
        "            icm4 = augmented['mask_icm']\n",
        "            te4 = augmented['mask_te']\n",
        "\n",
        "\n",
        "            I = [i, i1, i2, i3,i4]\n",
        "            ZP = [zp, zp1, zp2, zp3,zp4]\n",
        "            ICM = [icm, icm1, icm2, icm3,icm4]\n",
        "            TE = [te, te1, te2, te3,te4]\n",
        "\n",
        "            myvar3=myvar3+len(I)\n",
        "\n",
        "        else:\n",
        "            myvar2=myvar2+1 #another test/valid image processed\n",
        "\n",
        "            I = [i]\n",
        "            ZP = [zp]\n",
        "            ICM = [icm]\n",
        "            TE = [te]\n",
        "\n",
        "        index = 0\n",
        "        real_size = []\n",
        "        for i_aug, zp_aug, icm_aug, te_aug in zip(I, ZP, ICM, TE):\n",
        "\n",
        "            i_w, i_h = i_aug.shape[0], i_aug.shape[1]\n",
        "\n",
        "            i_res, zp_res, icm_res, te_res = resize_enhance(i_aug, zp_aug, icm_aug, te_aug)\n",
        "\n",
        "            if len(I) == 1:\n",
        "                i_name = f\"{name}.bmp\"\n",
        "                zp_name = f\"{name} ZP_Mask.bmp\"\n",
        "                icm_name = f\"{name} ICM_Mask.bmp\"\n",
        "                te_name = f\"{name} TE_Mask.bmp\"\n",
        "            else:\n",
        "                i_name = f\"{name}_{index}.bmp\"\n",
        "                zp_name = f\"{name} ZP_Mask_{index}.bmp\"\n",
        "                icm_name = f\"{name} ICM_Mask_{index}.bmp\"\n",
        "                te_name = f\"{name} TE_Mask_{index}.bmp\"\n",
        "                index += 1\n",
        "\n",
        "            i_path = os.path.join(new_path, \"images/\", i_name)\n",
        "            zp_path = os.path.join(new_path, \"GT_ZP/\", zp_name)\n",
        "            icm_path = os.path.join(new_path, \"GT_ICM/\", icm_name)\n",
        "            te_path = os.path.join(new_path, \"GT_TE/\", te_name)\n",
        "\n",
        "            real_size.append([i_name, i_w, i_h])\n",
        "\n",
        "            cv2.imwrite(i_path, i_res)\n",
        "            cv2.imwrite(zp_path, zp_res)\n",
        "            cv2.imwrite(icm_path, icm_res)\n",
        "            cv2.imwrite(te_path, te_res)\n",
        "            x=x+1\n",
        "\n",
        "        with open('/content/drive/MyDrive/PFA_Final/new_data/real_size.csv', 'a+', newline='\\n') as file:\n",
        "          writer = csv.writer(file)\n",
        "          writer.writerows(real_size)\n",
        "\n",
        "    print(\"nb train images \",myvar, \"non train images\",myvar2)\n",
        "    print(\"augmented total\",myvar3)\n",
        "    print(\"images stored total\",x)"
      ],
      "metadata": {
        "id": "AL_uzaWsp34G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the dataset\n",
        "drive_path = \"/content/drive/MyDrive/PFA_Final\"\n",
        "\n",
        "(train_i, test_i, valid_i), (train_zp, test_zp, valid_zp), (train_icm, test_icm, valid_icm), (train_te, test_te, valid_te)= load_data()\n",
        "\n",
        "create_dir(drive_path+\"/new_data/\")\n",
        "\n",
        "test_path = drive_path+\"/new_data/test/\"\n",
        "valid_path= drive_path+\"/new_data/valid/\"\n",
        "train_path= drive_path+\"/new_data/train/\"\n",
        "\n",
        "create_dir(train_path)\n",
        "create_dir(test_path)\n",
        "create_dir(valid_path)\n",
        "\n",
        "create_dir(test_path+\"images/\")\n",
        "create_dir(train_path+\"images/\")\n",
        "create_dir(valid_path+\"images/\")\n",
        "\n",
        "create_dir(test_path+\"GT_ZP/\")\n",
        "create_dir(train_path+\"GT_ZP/\")\n",
        "create_dir(valid_path+\"GT_ZP/\")\n",
        "\n",
        "create_dir(test_path+\"GT_ICM/\")\n",
        "create_dir(train_path+\"GT_ICM/\")\n",
        "create_dir(valid_path+\"GT_ICM/\")\n",
        "\n",
        "create_dir(test_path+\"GT_TE/\")\n",
        "create_dir(train_path+\"GT_TE/\")\n",
        "create_dir(valid_path+\"GT_TE/\")\n",
        "\n",
        "augment_data(test_i, test_zp, test_icm, test_te, test_path, train=False)\n",
        "augment_data(valid_i, valid_zp, valid_icm, valid_te, valid_path, train=False)\n",
        "augment_data(train_i, train_zp, train_icm, train_te, train_path, train=True)"
      ],
      "metadata": {
        "id": "_uv63JIZqJPd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7fc15a0-aaff-4852-f3fb-5c44cf4d5770"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total dataset: 249 249 249 249\n",
            "train, valid, test\n",
            "199 25 25\n",
            "25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25/25 [00:21<00:00,  1.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nb train images  0 non train images 25\n",
            "augmented total 0\n",
            "images stored total 25\n",
            "25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25/25 [00:15<00:00,  1.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nb train images  0 non train images 25\n",
            "augmented total 0\n",
            "images stored total 25\n",
            "199\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 199/199 [03:10<00:00,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nb train images  199 non train images 0\n",
            "augmented total 995\n",
            "images stored total 995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XwPxR3-cnk8p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}